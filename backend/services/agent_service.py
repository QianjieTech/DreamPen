"""
AI AgentæœåŠ¡ - åŸºäºLangGraphçš„åˆ›ä½œAgent
"""
from typing import TypedDict, Annotated, Sequence, Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from backend.core.config import settings
from backend.services.file_service import FileService


# ========== çŠ¶æ€å®šä¹‰ ==========

class AgentState(TypedDict):
    """AgentçŠ¶æ€"""
    messages: Annotated[Sequence[BaseMessage], "å¯¹è¯å†å²"]
    user_id: str
    project_id: str
    current_task: str  # worldview, outline, character, chapterç­‰
    context: dict  # ä»»åŠ¡ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    file_operations: list  # å¾…æ‰§è¡Œçš„æ–‡ä»¶æ“ä½œ
    next_action: str  # ä¸‹ä¸€æ­¥åŠ¨ä½œ


# ========== ä¸–ç•Œè§‚Agent ==========

class WorldviewAgent:
    """ä¸–ç•Œè§‚æ„å»ºAgent"""
    
    # ä»æç¤ºè¯æ–‡ä»¶æå–çš„ç³»ç»Ÿæç¤º
    SYSTEM_PROMPT = """ä½ æ˜¯ **Worldview Architect**,ä¸€ä¸ªä¸“ä¸šçš„å°è¯´ä¸–ç•Œè§‚æ„å»ºä¸“å®¶ã€‚ä½ çš„æ ¸å¿ƒç†å¿µæ˜¯é€šè¿‡æ‰å®çš„åŸºç¡€è®¾å®š,è®©æ•…äº‹ä¸–ç•Œè‡ªç„¶è¿è½¬ã€‚

æ ¸å¿ƒèŒè´£:
1. å¼•å¯¼å¼æ¢ç´¢:å¸®åŠ©ä½œè€…ä»é›¶æ•£çµæ„Ÿå‡ºå‘,é€æ­¥æ„å»ºå®Œæ•´ä¸–ç•Œè§‚
2. æ™ºèƒ½ç»´åº¦é€‰æ‹©:æ ¹æ®æ ¸å¿ƒåˆ›æ„å’Œå°è¯´ç±»å‹,åŠ¨æ€é€‰æ‹©é‡ç‚¹æ„å»ºçš„ç»´åº¦
3. é€»è¾‘è‡ªæ´½æ£€æŸ¥:ç¡®ä¿æ‰€æœ‰è®¾å®šä¹‹é—´ä¸å­˜åœ¨çŸ›ç›¾
4. åŸåˆ›æ€§ä¿æŠ¤:å¼•å¯¼ä½œè€…æå–å‚è€ƒä½œå“çš„ç»“æ„ç‰¹å¾,è€Œéç›´æ¥å¤åˆ¶å†…å®¹

æ ¸å¿ƒåŸåˆ™:
- æ¸è¿›å¼å¯¹è¯èŠ‚å¥:æ¯æ¬¡åªèšç„¦ä¸€ä¸ªç»´åº¦,ç­‰å¾…ç”¨æˆ·å……åˆ†å›ç­”
- åŠè‡ªåŠ¨è¾…åŠ©:æä¾›é€‰é¡¹è®©ç”¨æˆ·é€‰æ‹©,è€Œéå®Œå…¨å¼€æ”¾å¼æé—®
- ä¸€é—®ä¸€ç­”èŠ‚å¥:ä¸è¦åœ¨å•ä¸ªå›å¤ä¸­å †ç Œå¤§é‡ä¿¡æ¯

å·¥ä½œæµç¨‹:
1. æ”¶é›†æ ¸å¿ƒç§å­(ç”¨æˆ·çš„åˆå§‹çµæ„Ÿ)
2. å®Œå–„åŸºç¡€ç»´åº¦(ä¸–ç•Œç±»å‹ã€ç‰©ç†æ³•åˆ™ã€ç§æ—æ¦‚è§ˆ)
3. é€‰å®šå…³é”®ç»´åº¦(6-12ä¸ª)
4. è¡¥å……å¿…è¦ç»´åº¦(ç¡®ä¿æ€»æ•°â‰¥16ä¸ª)
5. é€»è¾‘è‡ªæ´½æ£€æŸ¥
6. ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£

åŸºç¡€ç»´åº¦(å¿…å¡«3ä¸ª):
1. ä¸–ç•Œç±»å‹ä¸æ ¸å¿ƒæ¦‚å¿µ
2. ç‰©ç†æ³•åˆ™/ä¸–ç•Œè§„åˆ™
3. ç§æ—/ç‰©ç§æ¦‚è§ˆ

ç»´åº¦æ± (Agentæ™ºèƒ½é€‰æ‹©):
- åœ°ç†ç©ºé—´ç»“æ„
- æ—¶é—´ä¸å†å²èƒŒæ™¯
- èƒ½é‡/é­”æ³•ä½“ç³»
- ä¿®ç‚¼/è¿›é˜¶è·¯å¾„
- ä¸»è¦åŠ¿åŠ›ä¸ç»„ç»‡
- ç¤¾ä¼šç»“æ„ä¸é˜¶å±‚
- æ”¿æ²»ä½“ç³»
- ç»æµä½“ç³»
- ç§‘æŠ€å‘å±•æ°´å¹³
- æ–‡åŒ–ä¸ä¹ ä¿—
- å®—æ•™/ä¿¡ä»°ä½“ç³»
- æ³•å®/è£…å¤‡ä½“ç³»
- ç‰¹æ®Šè§„åˆ™/ç¦å¿Œ
ç­‰ç­‰...

å¯¹è¯é£æ ¼:
- ä¸“ä¸šä½†å‹å¥½
- ç®€æ´æ˜ç¡®
- ä¸€æ¬¡åªé—®ä¸€ä¸ªä¸»è¦é—®é¢˜
- å…³é”®è®¾å®šç‚¹éœ€è¦å¤è¿°ç¡®è®¤

å½“ç”¨æˆ·è¡¨ç¤ºå®Œæˆæ”¶é›†ä¿¡æ¯å,ä½ éœ€è¦ç”Ÿæˆå®Œæ•´çš„ä¸–ç•Œè§‚Markdownæ–‡æ¡£ã€‚æ–‡æ¡£åº”è¯¥ç»“æ„æ¸…æ™°,åŒ…å«æ‰€æœ‰å·²ç¡®è®¤çš„ç»´åº¦è®¾å®šã€‚"""
    
    def __init__(self, llm: ChatOpenAI):
        """
        åˆå§‹åŒ–ä¸–ç•Œè§‚Agent
        
        Args:
            llm: OpenAIè¯­è¨€æ¨¡å‹
        """
        self.llm = llm
    
    async def chat_stream(
        self,
        user_message: str,
        conversation_history: list[BaseMessage],
        user_id: str,
        project_id: str
    ):
        """
        æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID
            project_id: é¡¹ç›®ID
            
        Yields:
            æµå¼å“åº”æ•°æ®å—
        """
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=self.SYSTEM_PROMPT),
            *conversation_history,
            HumanMessage(content=user_message)
        ]
        
        # æ£€æµ‹æ˜¯å¦éœ€è¦ç”Ÿæˆæ–‡æ¡£
        # æ–¹æ³•1: å…³é”®è¯æ£€æµ‹ï¼ˆç”¨æˆ·æ˜ç¡®è¦æ±‚ï¼‰
        keywords = ["ç”Ÿæˆæ–‡æ¡£", "ç”Ÿæˆä¸–ç•Œè§‚", "å®Œæˆæ„å»º", "åˆ›å»ºæ–‡ä»¶", "å†™å…¥æ–‡ä»¶", "ç”Ÿæˆåˆæ­¥æ–‡æ¡£",  "è·³è¿‡è®¾è®¡", "ç›´æ¥ç”Ÿæˆ"]
        user_message_lower = user_message.lower()
        keyword_found = any(keyword in user_message_lower for keyword in keywords)
        
        # æ–¹æ³•2: æ™ºèƒ½æ£€æµ‹ - æ£€æŸ¥å¯¹è¯å†å²æ˜¯å¦å·²æ”¶é›†å®Œæ•´ä¸–ç•Œè§‚ä¿¡æ¯
        should_auto_generate = await self._should_auto_generate_document(
            conversation_history + [HumanMessage(content=user_message)]
        )
        
        # å¦‚æœå…³é”®è¯æ£€æµ‹æˆ–æ™ºèƒ½æ£€æµ‹æ»¡è¶³ï¼Œåˆ™ç”Ÿæˆæ–‡æ¡£
        needs_document = keyword_found or should_auto_generate
        
        print(f"ğŸ”µ æµå¼å¤„ç† - å…³é”®è¯æ£€æµ‹: {keyword_found}, æ™ºèƒ½æ£€æµ‹: {should_auto_generate}, éœ€è¦ç”Ÿæˆ: {needs_document}")
        
        # æµå¼è°ƒç”¨LLM
        full_response = ""
        async for chunk in self.llm.astream(messages):
            if chunk.content:
                content = str(chunk.content)
                full_response += content
                yield {
                    'type': 'content',
                    'content': content
                }
        
        # å¦‚æœéœ€è¦ç”Ÿæˆæ–‡æ¡£
        if keyword_found:
            yield {
                'type': 'status',
                'message': 'æ­£åœ¨ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£...'
            }
            
            print(f"ğŸ”µ å¼€å§‹ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£...")
            
            # ç”Ÿæˆæ–‡æ¡£ï¼ˆä¹Ÿä½¿ç”¨æµå¼ï¼‰
            worldview_content = ""
            async for doc_chunk in self._generate_worldview_document_stream(
                conversation_history + [HumanMessage(content=user_message)],
                user_id,
                project_id
            ):
                worldview_content += doc_chunk
                yield {
                    'type': 'document',
                    'content': doc_chunk
                }
            
            print(f"ğŸ”µ æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(worldview_content)}")
            
            # è¿”å›æ–‡ä»¶æ“ä½œ
            yield {
                'type': 'file_operation',
                'operation': {
                    "action": "write",
                    "path": "01_settings/worldview.md",
                    "content": worldview_content
                }
            }
    
    async def chat(
        self,
        user_message: str,
        conversation_history: list[BaseMessage],
        user_id: str,
        project_id: str
    ) -> tuple[str, list[dict]]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆéæµå¼ï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID
            project_id: é¡¹ç›®ID
            
        Returns:
            (AIå›å¤, æ–‡ä»¶æ“ä½œåˆ—è¡¨)
        """
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=self.SYSTEM_PROMPT),
            *conversation_history,
            HumanMessage(content=user_message)
        ]
        
        # è°ƒç”¨LLM
        response = await self.llm.ainvoke(messages)
        ai_reply = str(response.content) if response.content else ""
        
        # æ£€æµ‹æ˜¯å¦éœ€è¦ç”Ÿæˆæ–‡æ¡£
        file_operations = []
        keywords = ["ç”Ÿæˆæ–‡æ¡£", "ç”Ÿæˆä¸–ç•Œè§‚", "å®Œæˆæ„å»º", "åˆ›å»ºæ–‡ä»¶", "å†™å…¥æ–‡ä»¶", "ç”Ÿæˆåˆæ­¥æ–‡æ¡£", "è·³è¿‡è®¾è®¡", "ç›´æ¥ç”Ÿæˆ"]
        
        user_message_lower = user_message.lower()
        keyword_found = any(keyword in user_message_lower for keyword in keywords)
        
        print(f"ğŸ”µ å…³é”®è¯æ£€æµ‹:")
        print(f"  - ç”¨æˆ·æ¶ˆæ¯: {user_message}")
        print(f"  - å°å†™æ¶ˆæ¯: {user_message_lower}")
        print(f"  - æ£€æµ‹åˆ°å…³é”®è¯: {keyword_found}")
        
        if keyword_found:
            print(f"ğŸ”µ å¼€å§‹ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£...")
            # ç”¨æˆ·è¯·æ±‚ç”Ÿæˆæ–‡æ¡£,éœ€è¦æ ¹æ®å¯¹è¯å†å²ç”Ÿæˆä¸–ç•Œè§‚å†…å®¹
            worldview_content = await self._generate_worldview_document(
                conversation_history + [HumanMessage(content=user_message)],
                user_id,
                project_id
            )
            
            print(f"ğŸ”µ æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(worldview_content)}")
            
            file_operations.append({
                "action": "write",
                "path": "01_settings/worldview.md",
                "content": worldview_content
            })
            
            print(f"ğŸ”µ file_operations: {[op['action'] + ': ' + op['path'] for op in file_operations]}")
        else:
            print(f"âŒ æœªæ£€æµ‹åˆ°å…³é”®è¯ï¼Œä¸ç”Ÿæˆæ–‡æ¡£")
        
        return ai_reply, file_operations
    
    async def _should_auto_generate_document(
        self,
        conversation_history: list[BaseMessage]
    ) -> bool:
        """
        æ™ºèƒ½æ£€æµ‹æ˜¯å¦åº”è¯¥è‡ªåŠ¨ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£
        
        é€šè¿‡åˆ†æå¯¹è¯å†å²ï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯å¦å·²ç»å®Œæˆäº†ä¸–ç•Œè§‚çš„æ ¸å¿ƒç»´åº¦è®¨è®º
        
        Args:
            conversation_history: å®Œæ•´å¯¹è¯å†å²
            
        Returns:
            æ˜¯å¦åº”è¯¥è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£
        """
        # å¦‚æœå¯¹è¯å¤ªçŸ­ï¼Œä¸è‡ªåŠ¨ç”Ÿæˆ
        if len(conversation_history) < 10:
            return False
        
        # æ£€æŸ¥æœ€è¿‘çš„å¯¹è¯æ˜¯å¦åŒ…å«å®Œæ•´çš„ä¸–ç•Œè§‚æè¿°
        # æŸ¥çœ‹æœ€åä¸€æ¡AIå›å¤æ˜¯å¦å¾ˆé•¿ä¸”åŒ…å«ä¸–ç•Œè§‚ç›¸å…³å†…å®¹
        if len(conversation_history) > 0:
            last_message = conversation_history[-1]
            if isinstance(last_message, AIMessage):
                content = str(last_message.content)
                
                # æ£€æŸ¥å†…å®¹é•¿åº¦ï¼ˆå®Œæ•´ä¸–ç•Œè§‚é€šå¸¸å¾ˆé•¿ï¼‰
                if len(content) < 1500:
                    return False
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šä¸ªæ ¸å¿ƒç»´åº¦çš„æ ‡å¿—
                dimension_indicators = [
                    "ä¸–ç•Œç±»å‹", "ç‰©ç†æ³•åˆ™", "ç§æ—", "åœ°ç†", "å†å²",
                    "é­”æ³•", "ç§‘æŠ€", "åŠ¿åŠ›", "ç¤¾ä¼š", "ç»æµ", "æ–‡åŒ–",
                    "æ ¸å¿ƒæ¦‚å¿µ", "ä¸–ç•Œè§‚", "è®¾å®š", "èƒŒæ™¯", "ä¸»çº¿"
                ]
                
                content_lower = content.lower()
                matched_dimensions = sum(1 for indicator in dimension_indicators if indicator in content_lower)
                
                # å¦‚æœåŒ¹é…äº†5ä¸ªä»¥ä¸Šçš„ç»´åº¦æ ‡å¿—ï¼Œè®¤ä¸ºæ˜¯å®Œæ•´ä¸–ç•Œè§‚
                if matched_dimensions >= 8:
                    print(f"ğŸŸ¢ æ™ºèƒ½æ£€æµ‹: å‘ç°å®Œæ•´ä¸–ç•Œè§‚æè¿° (åŒ¹é…ç»´åº¦: {matched_dimensions}/16)")
                    return True
        
        return False
    
    async def _generate_worldview_document_stream(
        self,
        conversation_history: list[BaseMessage],
        user_id: str,
        project_id: str
    ):
        """
        æµå¼ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£
        
        Args:
            conversation_history: å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID
            project_id: é¡¹ç›®ID
            
        Yields:
            æ–‡æ¡£å†…å®¹å—
        """
        summary_prompt = """è¯·åŸºäºä¹‹å‰çš„å¯¹è¯,ç”Ÿæˆä¸€ä»½å®Œæ•´çš„ä¸–ç•Œè§‚è®¾å®šæ–‡æ¡£ã€‚

æ–‡æ¡£æ ¼å¼è¦æ±‚:
1. ä½¿ç”¨Markdownæ ¼å¼
2. åŒ…å«æ¸…æ™°çš„æ ‡é¢˜å±‚çº§
3. æŒ‰ç…§ç»´åº¦åˆ†ç±»ç»„ç»‡å†…å®¹
4. ç¡®ä¿æ‰€æœ‰ç”¨æˆ·ç¡®è®¤çš„è®¾å®šéƒ½è¢«åŒ…å«

æ–‡æ¡£ç»“æ„å‚è€ƒ:
# [ä¸–ç•Œåç§°] ä¸–ç•Œè§‚è®¾å®š

## æ ¸å¿ƒæ¦‚å¿µ
[ç”¨ä¸€å¥è¯æ¦‚æ‹¬ä¸–ç•Œçš„ç‹¬ç‰¹æ€§]

## åŸºç¡€ç»´åº¦

### 1. ä¸–ç•Œç±»å‹
[è¯¦ç»†æè¿°]

### 2. ç‰©ç†æ³•åˆ™/ä¸–ç•Œè§„åˆ™
[è¯¦ç»†æè¿°]

### 3. ç§æ—/ç‰©ç§
[è¯¦ç»†æè¿°]

## å…³é”®ç»´åº¦

### [ç»´åº¦åç§°]
[è¯¦ç»†æè¿°]

...

## è¡¥å……ç»´åº¦

### [ç»´åº¦åç§°]
[ç®€è¦æè¿°]

...

è¯·æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆå®Œæ•´çš„æ–‡æ¡£å†…å®¹ã€‚"""
        
        messages = conversation_history + [
            HumanMessage(content=summary_prompt)
        ]
        
        # æµå¼ç”Ÿæˆ
        async for chunk in self.llm.astream(messages):
            if chunk.content:
                yield str(chunk.content)
    
    async def _generate_worldview_document(
        self,
        conversation_history: list[BaseMessage],
        user_id: str,
        project_id: str
    ) -> str:
        """
        æ ¹æ®å¯¹è¯å†å²ç”Ÿæˆä¸–ç•Œè§‚æ–‡æ¡£ï¼ˆéæµå¼ï¼‰
        
        Args:
            conversation_history: å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID
            project_id: é¡¹ç›®ID
            
        Returns:
            ä¸–ç•Œè§‚æ–‡æ¡£å†…å®¹
        """
        # æå–å¯¹è¯ä¸­çš„å…³é”®ä¿¡æ¯
        summary_prompt = """è¯·åŸºäºä¹‹å‰çš„å¯¹è¯,ç”Ÿæˆä¸€ä»½å®Œæ•´çš„ä¸–ç•Œè§‚è®¾å®šæ–‡æ¡£ã€‚

æ–‡æ¡£æ ¼å¼è¦æ±‚:
1. ä½¿ç”¨Markdownæ ¼å¼
2. åŒ…å«æ¸…æ™°çš„æ ‡é¢˜å±‚çº§
3. æŒ‰ç…§ç»´åº¦åˆ†ç±»ç»„ç»‡å†…å®¹
4. ç¡®ä¿æ‰€æœ‰ç”¨æˆ·ç¡®è®¤çš„è®¾å®šéƒ½è¢«åŒ…å«

æ–‡æ¡£ç»“æ„å‚è€ƒ:
# [ä¸–ç•Œåç§°] ä¸–ç•Œè§‚è®¾å®š

## æ ¸å¿ƒæ¦‚å¿µ
[ç”¨ä¸€å¥è¯æ¦‚æ‹¬ä¸–ç•Œçš„ç‹¬ç‰¹æ€§]

## åŸºç¡€ç»´åº¦

### 1. ä¸–ç•Œç±»å‹
[è¯¦ç»†æè¿°]

### 2. ç‰©ç†æ³•åˆ™/ä¸–ç•Œè§„åˆ™
[è¯¦ç»†æè¿°]

### 3. ç§æ—/ç‰©ç§
[è¯¦ç»†æè¿°]

## å…³é”®ç»´åº¦

### [ç»´åº¦åç§°]
[è¯¦ç»†æè¿°]

...

## è¡¥å……ç»´åº¦

### [ç»´åº¦åç§°]
[ç®€è¦æè¿°]

...

è¯·æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆå®Œæ•´çš„æ–‡æ¡£å†…å®¹ã€‚"""
        
        messages = conversation_history + [
            HumanMessage(content=summary_prompt)
        ]
        
        response = await self.llm.ainvoke(messages)
        return str(response.content) if response.content else ""


# ========== Agentå·¥ä½œæµ(é¢„ç•™) ==========

class CreativeAgentWorkflow:
    """
    åˆ›ä½œAgentå·¥ä½œæµ - åŸºäºLangGraph
    
    è¿™æ˜¯ä¸€ä¸ªé¢„ç•™çš„å·¥ä½œæµæ¡†æ¶,ç”¨äºæœªæ¥æ‰©å±•å¤šAgentåä½œ
    ç›®å‰ä»…å®ç°äº†ä¸–ç•Œè§‚Agentçš„ç®€åŒ–ç‰ˆæœ¬
    """
    
    def __init__(self, llm: ChatOpenAI):
        """
        åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            llm: OpenAIè¯­è¨€æ¨¡å‹
        """
        self.llm = llm
        self.worldview_agent = WorldviewAgent(llm)
        # TODO: æ·»åŠ å…¶ä»–Agent
        # self.character_agent = CharacterAgent(llm)
        # self.outline_agent = OutlineAgent(llm)
        # etc.
    
    def _build_graph(self):
        """
        æ„å»ºLangGraphå·¥ä½œæµå›¾
        
        Returns:
            ç¼–è¯‘åçš„å›¾
        """
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("router", self._route_task)
        workflow.add_node("worldview", self._handle_worldview)
        workflow.add_node("file_ops", self._execute_file_operations)
        workflow.add_node("summarize", self._summarize_result)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("router")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "router",
            self._determine_agent_type,
            {
                "worldview": "worldview",
                "continue": "summarize"
            }
        )
        
        # æ·»åŠ å›ºå®šè¾¹
        workflow.add_edge("worldview", "file_ops")
        workflow.add_edge("file_ops", "summarize")
        workflow.add_edge("summarize", END)
        
        return workflow.compile()
    
    def _determine_agent_type(self, state: AgentState) -> Literal["worldview", "continue"]:
        """ç¡®å®šAgentç±»å‹"""
        # ç®€åŒ–ç‰ˆæœ¬:ç›´æ¥è¿”å›worldview
        return "worldview"
    
    def _route_task(self, state: AgentState) -> AgentState:
        """è·¯ç”±ä»»åŠ¡"""
        state["current_task"] = "worldview"
        return state
    
    def _handle_worldview(self, state: AgentState) -> AgentState:
        """å¤„ç†ä¸–ç•Œè§‚ä»»åŠ¡"""
        # è¿™é‡Œæ˜¯å ä½å®ç°,å®é™…ä½¿ç”¨æ—¶éœ€è¦å¼‚æ­¥å¤„ç†
        return state
    
    def _execute_file_operations(self, state: AgentState) -> AgentState:
        """æ‰§è¡Œæ–‡ä»¶æ“ä½œ"""
        state["next_action"] = "write_file"
        return state
    
    def _summarize_result(self, state: AgentState) -> AgentState:
        """æ€»ç»“ç»“æœ"""
        state["next_action"] = "complete"
        return state


# ========== Agentå·¥å‚ ==========

class AgentFactory:
    """Agentå·¥å‚"""
    
    @staticmethod
    def create_worldview_agent() -> WorldviewAgent:
        """
        åˆ›å»ºä¸–ç•Œè§‚Agent
        
        Returns:
            ä¸–ç•Œè§‚Agentå®ä¾‹
        """
        llm = ChatOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
            model=settings.openai_model,
            temperature=settings.openai_temperature
        )
        return WorldviewAgent(llm)
    
    @staticmethod
    def create_workflow() -> CreativeAgentWorkflow:
        """
        åˆ›å»ºå®Œæ•´å·¥ä½œæµ
        
        Returns:
            å·¥ä½œæµå®ä¾‹
        """
        llm = ChatOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
            model=settings.openai_model,
            temperature=settings.openai_temperature
        )
        return CreativeAgentWorkflow(llm)