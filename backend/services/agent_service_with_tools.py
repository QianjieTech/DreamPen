"""
AI AgentæœåŠ¡ - æ”¯æŒå·¥å…·è°ƒç”¨çš„ç‰ˆæœ¬
"""
from typing import AsyncGenerator
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from backend.core.config import settings
from backend.services.tools import create_file_tools


class WorldviewAgentWithTools:
    """ä¸–ç•Œè§‚æ„å»ºAgent - æ”¯æŒå·¥å…·è°ƒç”¨"""
    
    def __init__(self, user_id: str, project_id: str, custom_prompt: str | None = None):
        """
        åˆå§‹åŒ–ä¸–ç•Œè§‚Agent
        
        Args:
            user_id: ç”¨æˆ·ID  
            project_id: é¡¹ç›®ID
            custom_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        """
        self.user_id = user_id
        self.project_id = project_id
        self.custom_prompt = custom_prompt
        
        # åˆ›å»ºLLMï¼ˆå¯ç”¨å·¥å…·è°ƒç”¨ï¼‰
        self.llm = ChatOpenAI(
            api_key=settings.openai_api_key,
            base_url=settings.openai_base_url,
            model=settings.openai_model,
            temperature=settings.openai_temperature
        )
        
        # åˆ›å»ºæ–‡ä»¶æ“ä½œå·¥å…·
        self.tools = create_file_tools(user_id, project_id)
        
        # å°†å·¥å…·ç»‘å®šåˆ°LLM
        self.llm_with_tools = self.llm.bind_tools(self.tools)
    
    def _get_system_prompt(self) -> str:
        """
        è·å–ç³»ç»Ÿæç¤ºè¯
        
        Returns:
            ç³»ç»Ÿæç¤ºè¯å†…å®¹
        """
        # å·¥å…·ä½¿ç”¨æŒ‡ä»¤ï¼ˆæ— è®ºä½¿ç”¨å“ªä¸ªæç¤ºè¯éƒ½è¦é™„åŠ ï¼‰
        tool_instructions = """

---
**ğŸ› ï¸ æ–‡ä»¶æ“ä½œå·¥å…·ï¼ˆé‡è¦ï¼‰**ï¼š

ä½ æ‹¥æœ‰ä»¥ä¸‹å·¥å…·ï¼Œå¿…é¡»åœ¨éœ€è¦æ—¶ç«‹å³ä½¿ç”¨ï¼š
1. **read_file(file_path)** - è¯»å–æ–‡ä»¶
2. **write_to_file(file_path, content)** - å†™å…¥/åˆ›å»ºæ–‡ä»¶
3. **list_files(directory)** - åˆ—å‡ºç›®å½•
4. **create_directory(directory_path)** - åˆ›å»ºç›®å½•

**æ‰§è¡ŒåŸåˆ™**ï¼š
ğŸš¨ **ç«‹å³æ‰§è¡Œï¼Œä¸è¦è§£é‡Š** - ä¸è¦è¯´"æˆ‘å°†..."ï¼Œç›´æ¥è°ƒç”¨å·¥å…·
- éœ€è¦æŸ¥çœ‹ â†’ ç›´æ¥ read_file
- éœ€è¦å†™å…¥ â†’ ç›´æ¥ write_to_file
- éœ€è¦æµè§ˆ â†’ ç›´æ¥ list_files

**é”™è¯¯ç¤ºèŒƒ** âŒï¼š
"å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ›å»ºè§’è‰²å¡..." [åªè¯´ä¸åš]

**æ­£ç¡®ç¤ºèŒƒ** âœ…ï¼š
[ç«‹å³è°ƒç”¨ write_to_file("02_characters/xxx.md", content)]
"âœ… è§’è‰²å¡å·²åˆ›å»ºï¼"

**æ–‡ä»¶è·¯å¾„**ï¼š
- ä¸–ç•Œè§‚ï¼š01_settings/worldview.md
- è§’è‰²å¡ï¼š02_characters/è§’è‰²å.md
- å‰§æƒ…ï¼š03_story/xxx.md

å…ˆè¡ŒåŠ¨ï¼Œåè¯´è¯ã€‚ç”¨æˆ·è¦ç»“æœï¼Œä¸è¦æ‰¿è¯ºã€‚
---
"""
        
        if self.custom_prompt:
            # è‡ªå®šä¹‰æç¤ºè¯ + å·¥å…·ä½¿ç”¨æŒ‡ä»¤
            return self.custom_prompt + tool_instructions
        
        # é»˜è®¤æç¤ºè¯
        return """ä½ æ˜¯ **Worldview Architect**ï¼Œä¸€ä¸ªä¸“ä¸šçš„å°è¯´ä¸–ç•Œè§‚æ„å»ºä¸“å®¶ã€‚

ä½ æ‹¥æœ‰ä»¥ä¸‹æ–‡ä»¶æ“ä½œå·¥å…·ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š

1. **read_file(file_path)** - è¯»å–æ–‡ä»¶å†…å®¹
2. **write_to_file(file_path, content)** - å†™å…¥/åˆ›å»ºæ–‡ä»¶
3. **list_files(directory)** - åˆ—å‡ºç›®å½•æ–‡ä»¶
4. **create_directory(directory_path)** - åˆ›å»ºç›®å½•

**æ‰§è¡ŒåŸåˆ™ï¼ˆéå¸¸é‡è¦ï¼‰**ï¼š

ğŸš¨ **ç«‹å³æ‰§è¡Œï¼Œä¸è¦è§£é‡Š**ï¼š
- å½“éœ€è¦æŸ¥çœ‹æ–‡ä»¶æ—¶ï¼Œç›´æ¥è°ƒç”¨ read_fileï¼Œä¸è¦è¯´"æˆ‘å°†æŸ¥çœ‹"
- å½“éœ€è¦å†™å…¥æ–‡ä»¶æ—¶ï¼Œç›´æ¥è°ƒç”¨ write_to_fileï¼Œä¸è¦è¯´"æˆ‘å°†å†™å…¥"
- å½“éœ€è¦æµè§ˆç›®å½•æ—¶ï¼Œç›´æ¥è°ƒç”¨ list_filesï¼Œä¸è¦è¯´"æˆ‘å°†åˆ—å‡º"
- **å…ˆè¡ŒåŠ¨ï¼Œåè¯´è¯**ï¼šå…ˆè°ƒç”¨å·¥å…·è·å–ç»“æœï¼Œç„¶ååŸºäºç»“æœç»™ç”¨æˆ·åé¦ˆ

**é”™è¯¯ç¤ºèŒƒ** âŒï¼š
ç”¨æˆ·ï¼š"åˆ›å»ºè§’è‰²å¡"
ä½ ï¼š"å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ›å»ºè§’è‰²å¡..." [åœæ­¢ï¼Œç­‰å¾…ç”¨æˆ·]

**æ­£ç¡®ç¤ºèŒƒ** âœ…ï¼š
ç”¨æˆ·ï¼š"åˆ›å»ºè§’è‰²å¡"
ä½ ï¼š[ç«‹å³è°ƒç”¨ write_to_file("02_characters/xxx.md", content)]
ç„¶åï¼š"âœ… è§’è‰²å¡å·²åˆ›å»ºå®Œæˆï¼..."

**å·¥ä½œæµç¨‹**ï¼š
1. éœ€è¦äº†è§£ç°çŠ¶ â†’ ç›´æ¥è°ƒç”¨ list_files æˆ– read_file
2. éœ€è¦åˆ›å»ºå†…å®¹ â†’ ç›´æ¥è°ƒç”¨ write_to_file
3. çœ‹åˆ°å·¥å…·æ‰§è¡Œç»“æœå â†’ å‘ç”¨æˆ·è§£é‡Šå’Œæ€»ç»“

**æ–‡ä»¶è·¯å¾„è§„èŒƒ**ï¼š
- ä¸–ç•Œè§‚ï¼š01_settings/worldview.md
- è§’è‰²å¡ï¼š02_characters/è§’è‰²å.md
- å‰§æƒ…ï¼š03_story/xxx.md

è®°ä½ï¼šä½ æœ‰çœŸå®çš„æ–‡ä»¶æ“ä½œèƒ½åŠ›ï¼ä¸è¦å½“ä¸ª"å˜´å¼ºç‹è€…"ï¼Œè¦å½“ä¸ª"è¡ŒåŠ¨æ´¾"ã€‚ç”¨æˆ·è¦çš„æ˜¯ç»“æœï¼Œä¸æ˜¯æ‰¿è¯ºã€‚"""
    
    def set_prompt(self, prompt_content: str):
        """
        åŠ¨æ€è®¾ç½®æç¤ºè¯
        
        Args:
            prompt_content: æ–°çš„æç¤ºè¯å†…å®¹
        """
        self.custom_prompt = prompt_content
    
    async def chat_stream(
        self,
        user_message: str,
        conversation_history: list[BaseMessage]
    ) -> AsyncGenerator[dict, None]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            
        Yields:
            æµå¼å“åº”æ•°æ®å—
        """
        from langchain_core.messages import ToolMessage
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=self._get_system_prompt()),
            *conversation_history,
            HumanMessage(content=user_message)
        ]
        
        # Agentå¾ªç¯ï¼šå¯èƒ½éœ€è¦å¤šè½®å·¥å…·è°ƒç”¨
        max_iterations = 5
        iteration = 0
        
        while iteration < max_iterations:
            iteration += 1
            print(f"[Agent] ç¬¬ {iteration} è½®æ¨ç†...")
            
            # LLMå“åº”ï¼ˆå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ï¼‰
            full_response = ""
            tool_calls = []
            
            async for chunk in self.llm_with_tools.astream(messages):
                # å¤„ç†å†…å®¹
                if chunk.content:
                    content = str(chunk.content)
                    full_response += content
                    yield {
                        'type': 'content',
                        'content': content
                    }
                
                # æ”¶é›†å·¥å…·è°ƒç”¨
                if hasattr(chunk, 'tool_calls') and chunk.tool_calls:
                    tool_calls.extend(chunk.tool_calls)
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜å¯¹è¯ç»“æŸ
            if not tool_calls:
                print(f"[Agent] æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå¯¹è¯ç»“æŸ")
                break
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            yield {
                'type': 'status',
                'message': f'æ­£åœ¨æ‰§è¡Œ {len(tool_calls)} ä¸ªæ“ä½œ...'
            }
            
            # å°†AIæ¶ˆæ¯æ·»åŠ åˆ°å†å²
            messages.append(AIMessage(
                content=full_response,
                tool_calls=tool_calls
            ))
            
            # æ‰§è¡Œæ¯ä¸ªå·¥å…·
            for tool_call in tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                tool_call_id = tool_call['id']
                
                print(f"[Agent] å·¥å…·è°ƒç”¨: {tool_name}({tool_args})")
                
                # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                tool_func = None
                for tool in self.tools:
                    if tool.name == tool_name:
                        tool_func = tool
                        break
                
                if tool_func:
                    try:
                        # æ‰§è¡Œå·¥å…·
                        result = await tool_func.ainvoke(tool_args)
                        
                        yield {
                            'type': 'tool_result',
                            'tool_name': tool_name,
                            'result': result
                        }
                        
                        # å¦‚æœæ˜¯å†™å…¥æ–‡ä»¶æ“ä½œï¼Œé¢å¤–è¿”å›æ–‡ä»¶æ“ä½œä¿¡æ¯
                        if tool_name == 'write_to_file' and 'âœ…' in result:
                            yield {
                                'type': 'file_operation',
                                'operation': {
                                    'action': 'write',
                                    'path': tool_args.get('file_path', ''),
                                    'content': tool_args.get('content', '')
                                }
                            }
                        
                        print(f"[Agent] å·¥å…·æ‰§è¡ŒæˆåŠŸ: {result[:100]}...")
                        
                        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append(ToolMessage(
                            content=result,
                            tool_call_id=tool_call_id
                        ))
                        
                    except Exception as e:
                        error_msg = f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                        print(f"[Agent] {error_msg}")
                        yield {
                            'type': 'tool_result',
                            'tool_name': tool_name,
                            'result': error_msg
                        }
                        
                        # å°†é”™è¯¯ç»“æœä¹Ÿæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append(ToolMessage(
                            content=error_msg,
                            tool_call_id=tool_call_id
                        ))
                else:
                    error_msg = f"âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}"
                    print(f"[Agent] {error_msg}")
                    messages.append(ToolMessage(
                        content=error_msg,
                        tool_call_id=tool_call_id
                    ))
            
            # ç»§ç»­ä¸‹ä¸€è½®ï¼ˆLLMä¼šæ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå“åº”ï¼‰
            print(f"[Agent] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®æ¨ç†...")
    
    async def chat(
        self,
        user_message: str,
        conversation_history: list[BaseMessage]
    ) -> tuple[str, list[dict]]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆéæµå¼ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            (AIå›å¤, æ–‡ä»¶æ“ä½œåˆ—è¡¨)
        """
        from langchain_core.messages import ToolMessage
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            SystemMessage(content=self._get_system_prompt()),
            *conversation_history,
            HumanMessage(content=user_message)
        ]
        
        file_operations = []
        final_reply = ""
        
        # Agentå¾ªç¯ï¼šå¯èƒ½éœ€è¦å¤šè½®å·¥å…·è°ƒç”¨
        max_iterations = 5
        iteration = 0
        
        while iteration < max_iterations:
            iteration += 1
            print(f"[Agent] ç¬¬ {iteration} è½®æ¨ç†...")
            
            # LLMå“åº”ï¼ˆå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ï¼‰
            response = await self.llm_with_tools.ainvoke(messages)
            ai_reply = str(response.content) if response.content else ""
            
            # å¦‚æœæœ‰å†…å®¹ï¼Œè®°å½•ä¸‹æ¥
            if ai_reply:
                final_reply = ai_reply
            
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜å¯¹è¯ç»“æŸ
            if not hasattr(response, 'tool_calls') or not response.tool_calls:
                print(f"[Agent] æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå¯¹è¯ç»“æŸ")
                break
            
            # å°†AIæ¶ˆæ¯æ·»åŠ åˆ°å†å²
            messages.append(AIMessage(
                content=ai_reply,
                tool_calls=response.tool_calls
            ))
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in response.tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                tool_call_id = tool_call['id']
                
                print(f"[Agent] å·¥å…·è°ƒç”¨: {tool_name}({tool_args})")
                
                # æŸ¥æ‰¾å¯¹åº”çš„å·¥å…·
                tool_func = None
                for tool in self.tools:
                    if tool.name == tool_name:
                        tool_func = tool
                        break
                
                if tool_func:
                    try:
                        # æ‰§è¡Œå·¥å…·
                        result = await tool_func.ainvoke(tool_args)
                        print(f"[Agent] å·¥å…·æ‰§è¡ŒæˆåŠŸ: {result[:100]}...")
                        
                        # å¦‚æœæ˜¯å†™å…¥æ–‡ä»¶æ“ä½œï¼Œè®°å½•åˆ°file_operations
                        if tool_name == 'write_to_file' and 'âœ…' in result:
                            file_operations.append({
                                'action': 'write',
                                'path': tool_args.get('file_path', ''),
                                'content': tool_args.get('content', '')
                            })
                        
                        # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append(ToolMessage(
                            content=result,
                            tool_call_id=tool_call_id
                        ))
                        
                    except Exception as e:
                        error_msg = f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
                        print(f"[Agent] {error_msg}")
                        
                        # å°†é”™è¯¯ç»“æœä¹Ÿæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                        messages.append(ToolMessage(
                            content=error_msg,
                            tool_call_id=tool_call_id
                        ))
                else:
                    error_msg = f"âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}"
                    print(f"[Agent] {error_msg}")
                    messages.append(ToolMessage(
                        content=error_msg,
                        tool_call_id=tool_call_id
                    ))
            
            # ç»§ç»­ä¸‹ä¸€è½®ï¼ˆLLMä¼šæ ¹æ®å·¥å…·ç»“æœç”Ÿæˆå“åº”ï¼‰
            print(f"[Agent] å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®æ¨ç†...")
        
        return final_reply, file_operations


class AgentFactoryWithTools:
    """Agentå·¥å‚ - å·¥å…·ç‰ˆæœ¬"""
    
    @staticmethod
    def create_worldview_agent(
        user_id: str,
        project_id: str,
        custom_prompt: str | None = None
    ) -> WorldviewAgentWithTools:
        """
        åˆ›å»ºä¸–ç•Œè§‚Agentï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            project_id: é¡¹ç›®ID
            custom_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            ä¸–ç•Œè§‚Agentå®ä¾‹
        """
        return WorldviewAgentWithTools(user_id, project_id, custom_prompt)